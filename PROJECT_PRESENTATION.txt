# Описание проекта Job Parser System

## Кратко о проекте
Job Parser System — система для автоматического поиска и сбора вакансий с крупнейших платформ HH.ru и SuperJob.ru с возможностью просмотра, фильтрации и сохранения результатов в базе данных. Поддерживает асинхронный поиск, экспорт в CSV, CLI-режим и удобный веб-интерфейс.

---

## Использованные технологии
- **Python** — основной язык программирования
- **Flask** — веб-фреймворк для backend и frontend
- **requests** — для HTTP-запросов и работы с API
- **BeautifulSoup** — для парсинга HTML-страниц (HH.ru)
- **SQLAlchemy** — для работы с базой данных (ORM)
- **SQLite** — встроенная база данных для хранения вакансий
- **SuperJob API** — официальный API для получения вакансий
- **HTML, CSS, JS** — для пользовательского интерфейса
- **threading** — для асинхронного поиска на backend
- **Selenium** (ранее, сейчас не используется) — для обхода защиты сайтов

---

## Основные возможности
- Поиск вакансий на HH.ru (через requests + BeautifulSoup) и SuperJob.ru (через официальный API)
- Асинхронный поиск с индикатором загрузки и опросом статуса задачи
- Сохранение вакансий в SQLite через SQLAlchemy (без дублей)
- Просмотр вакансий в браузере (JSON, текст)
- Экспорт только текущих результатов поиска в CSV (с BOM для Excel)
- CLI-скрипт для поиска и сохранения новых вакансий
- Пагинация и сортировка по зарплате
- Ограничение количества страниц при парсинге для ускорения
- Устойчивость к ошибкам и блокировкам

---

## Архитектура
- **Backend (Flask):**
    - Эндпоинты для поиска, просмотра, выгрузки вакансий
    - Асинхронный парсинг (background thread)
    - Сохранение в SQLite
- **Frontend (Flask + HTML + JS):**
    - Форма поиска с выбором сайта, количества, сортировки
    - Индикатор загрузки, экспорт в CSV
    - Опрос статуса задачи через JS
- **CLI:**
    - Поиск и сохранение новых вакансий через консоль
    - Сортировка, ограничение количества, экспорт в JSON

---

## Как пользоваться
### Веб-интерфейс
1. Запустите backend и frontend (см. RUN_MANUAL.txt)
2. Откройте http://localhost:8000
3. Введите параметры поиска, нажмите "Поиск"
4. Дождитесь завершения (индикатор загрузки)
5. Просмотрите результаты, экспортируйте в CSV при необходимости

### CLI-режим
1. Перейдите в папку backend
2. Запустите: `python cli_search.py`
3. Следуйте инструкциям в консоли (выбор сайта, ввод вакансии, количества, сортировка)
4. Новые вакансии сохраняются в файл vacancies_cli.json

---

## Советы и рекомендации
- Для ускорения работы используйте асинхронный режим и ограничивайте количество страниц
- Для корректного экспорта в Excel используйте CSV с BOM
- Если возникают ошибки 404 — проверьте адреса API в JS/HTML
- Для запуска через Docker используйте docker-compose.yml

---

## Подробнее о запуске
См. файл RUN_MANUAL.txt (подробная инструкция по запуску и настройке)

---

**Проект легко расширяется и может быть доработан под любые задачи!** 